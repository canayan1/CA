# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E-nkhlVl2oFh-eFE0jsXl2Z2QMzECRiU
"""



"""Importing Libraries"""

import pandas as pd
import numpy as np 
import seaborn as sns
import matplotlib.pyplot as plt
import missingno as msno

from scipy import stats
from sklearn.metrics import f1_score,confusion_matrix,classification_report
from sklearn.feature_selection import f_classif
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_selection import SelectKBest

from sklearn.ensemble import RandomForestClassifier

import itertools
import numpy as np

import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec

from sklearn import datasets

from sklearn.tree import DecisionTreeClassifier
 
from sklearn.linear_model import LogisticRegression, LinearRegression
#from sklearn.ensemble import RandomForestClassifier

from sklearn.ensemble import BaggingClassifier, BaggingRegressor
from sklearn.model_selection import cross_val_score, train_test_split
import warnings
warnings.filterwarnings('ignore')

pd.set_option('display.max_columns', None)

"""Reading Dataset and Preparation

```
# This is formatted as code
```

Reading Dataset and Preparation
"""

df=pd.read_csv("heart.csv")
df.head()

print(str(df))

dict_nunique={}
for i in df.columns:
    key,value=i,df[i].nunique()
    dict_nunique[key]=value
    
print(dict_nunique)

categoric=["sex","cp","fbs","restecg","exng","slp","caa","thall"]
#categorical variables are already encoded form in the dataset.

df.info

df.duplicated().sum()

df.describe().T

df.isna().sum()

df.groupby("sex").mean()
df.groupby("cp").mean()

df_std.head()

"""Visualization

```
# This is formatted as code
```



"""

df["output"].value_counts()

sns.countplot(df["output"])

fig,axes = plt.subplots(1, 3, figsize=(15,6), sharey=False)
fig.suptitle("Comparison of Output")
sns.countplot(ax=axes[0], data=df , x="fbs" , hue="output")
sns.countplot(ax=axes[1], data=df , x="sex" ,hue="output")
sns.countplot(ax=axes[2], data=df , x="cp" ,  hue="output")

for column in categoric:
             df[column]=df[column].astype("category")
 
from sklearn.preprocessing import MinMaxScaler

numerics=df.select_dtypes(exclude="category").drop("output",axis=1)

outlier_index=[]
MinMaxScaler=MinMaxScaler()
df_std=df.copy()
for column in numerics.columns:
    df_std[[column]] = MinMaxScaler.fit_transform(df_std[[column]])
    outlier_index.extend(df[(df[column] < df[column].mean() - 3*df[column].std()) | (df[column] > df[column].mean() + 3*df[column].std())].index)
    

df_std.head()

len(set(outlier_index))

df.drop(set(outlier_index),inplace=True)

plt.figure(figsize=(20,25))
for i in enumerate(numerics.columns):
    plt.subplot(6,3,i[0]+1)
    sns.kdeplot(i[1], shade=True,hue="output",data=df_std)

from sklearn.metrics import plot_confusion_matrix

column_names=["model","precision0","recall0","f1-score0","precision1","recall1","f1-score1","accuracy"]

from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression,SGDClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.naive_bayes import GaussianNB

Logit = LogisticRegression(solver='liblinear',random_state = 101)
Sgdc = SGDClassifier(random_state = 101)
Knn = KNeighborsClassifier()
Dtree = DecisionTreeClassifier(random_state = 101)
Rndfr = RandomForestClassifier(random_state = 101)
Mlp = MLPClassifier(random_state = 101)
Xgb = XGBClassifier(random_state = 101,eval_metric='mlogloss')
Gnb = GaussianNB()

Algorithms =[Logit,Knn,Dtree,Mlp,Sgdc,Gnb,Rndfr]



Algorithms =[Logit,Knn,Dtree,Mlp,Sgdc,Gnb,Rndfr]

List_of_scores=[] 
for_iteration=0

for i in datasets:
    X=df.drop("output",axis=1)
    y=df["output"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=101)

for k in Algorithms:
        model=k.fit(X_train,y_train)
        y_pred=model.predict(X_test)
        report = classification_report(y_test, y_pred, output_dict=True)
        values = (pd.DataFrame(report).T.iloc[0:3,0:3].values).reshape((1,9))[0][0:7].tolist()
        values.insert(0,str(k).split("(")[0]+"_"+datanames[for_iteration])
        List_of_scores.append(values)

results = pd.DataFrame(data=List_of_scores,columns=column_names)
results = results.sort_values("accuracy",ascending=False)
results

"""# New Section"""

selected_Algo=[Gnb,Dtree,Logit,Rndfr]

List_test_scores=[] 
test_size=[0.1,0.2,0.3,0.4,0.5]

for i in test_size:

    X=df.drop("output",axis=1)
    y=df["output"]
        
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i , random_state=101)
    for k in selected_Algo:    
        model=k.fit(X_train,y_train)
        y_pred=model.predict(X_test)
        report = classification_report(y_test, y_pred, output_dict=True)
        values = (pd.DataFrame(report).T.iloc[0:3,0:3].values).reshape((1,9))[0][0:7].tolist()
        values.insert(0,str(k).split("(")[0]+"test_size{}".format(i))
        
        List_test_scores.append(values)

results_test=pd.DataFrame(data=List_test_scores,columns=column_names)
results_test.sort_values("f1-score1",ascending=False)